{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33dc1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TicTacToeEnv import TicTacToeAdvanced\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Categorical\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c02a768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, gamma=0.99, batch_size=128, \n",
    "                 epsilon=0.2, epoch_n=100, pi_lr=1e-4, v_lr=1e-3):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.pi_model_base = nn.Sequential(nn.Linear(state_dim, 256), nn.LeakyReLU(0.1),\n",
    "                                           nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
    "                                           nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
    "                                      nn.Linear(256, 256), nn.LeakyReLU(0.1)).to(self.device)\n",
    "        self.pi_model_m = nn.Sequential(nn.Linear(256, action_dim), nn.Softmax()).to(self.device)\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.l_epsilon = 1\n",
    "        self.epsilon = epsilon\n",
    "        self.epoch_n = epoch_n\n",
    "        self.pi_optimizer = torch.optim.Adam(\n",
    "            list(self.pi_model_base.parameters())+list(self.pi_model_m.parameters()),\n",
    "            lr=pi_lr)\n",
    "        \n",
    "    def forward_pi(self, state):\n",
    "        x = self.pi_model_base(state)\n",
    "        \n",
    "        return self.pi_model_m(x)\n",
    "\n",
    "    def get_action(self, state, rand_factor = 1):\n",
    "        logits = self.forward_pi(torch.FloatTensor(state))\n",
    "        norm = torch.ones((self.action_dim,))/self.action_dim\n",
    "        logits_ = (1-self.l_epsilon)*logits + self.l_epsilon*norm\n",
    "        dist = Categorical(logits_)\n",
    "        action = dist.sample()\n",
    "        return action.numpy()\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        self.pi_model_base.to('cpu')\n",
    "        self.pi_model_m.to('cpu')\n",
    "        \n",
    "    def to_dev(self):\n",
    "        self.pi_model_base.to(self.device)\n",
    "        self.pi_model_m.to(self.device)\n",
    "\n",
    "    def fit(self, states, actions, rewards, dones):\n",
    "        \n",
    "        states, actions, rewards, dones = map(np.array, [states, actions, rewards, dones])\n",
    "        rewards, dones = rewards.reshape(-1, 1), dones.reshape(-1, 1)\n",
    "\n",
    "        returns = np.zeros(rewards.shape)\n",
    "        returns[-1] = rewards[-1]\n",
    "        for t in range(returns.shape[0] - 2, -1, -1):\n",
    "            returns[t] = rewards[t] + (1 - dones[t]) * self.gamma * returns[t + 1]\n",
    "        for t in range(returns.shape[0]):\n",
    "            if returns[t] < 0:\n",
    "                returns[t] *= 0.8\n",
    "\n",
    "        states, actions, returns = map(torch.FloatTensor, [states, actions, returns])\n",
    "        states, actions, returns = states.to(self.device), actions.to(self.device), returns.to(self.device)\n",
    "\n",
    "        logits = self.forward_pi(states)\n",
    "        norm = (torch.ones((self.action_dim,))/self.action_dim).to(self.device)\n",
    "        logits_ = (1-self.l_epsilon)*logits + self.l_epsilon*norm\n",
    "        dist = Categorical(logits_)\n",
    "        old_log_probs = dist.log_prob(actions).detach()\n",
    "\n",
    "        for epoch in range(self.epoch_n):\n",
    "            \n",
    "            idxs = np.random.permutation(returns.shape[0])\n",
    "            for i in range(0, returns.shape[0], self.batch_size):\n",
    "                b_idxs = idxs[i: i + self.batch_size]\n",
    "                b_states = states[b_idxs]\n",
    "                b_actions = actions[b_idxs]\n",
    "                b_returns = returns[b_idxs]\n",
    "                b_old_log_probs = old_log_probs[b_idxs]\n",
    "    \n",
    "                b_advantage = b_returns.detach()\n",
    "                \n",
    "                b_logits = self.forward_pi(b_states)\n",
    "                b_dist = Categorical(b_logits)\n",
    "                b_new_log_probs = b_dist.log_prob(b_actions)\n",
    "    \n",
    "                b_ratio = torch.exp(b_new_log_probs - b_old_log_probs)\n",
    "                pi_loss_1 = b_ratio * b_advantage.detach()\n",
    "                pi_loss_2 = torch.clamp(b_ratio, 1. - self.epsilon,  1. + self.epsilon) * b_advantage.detach()\n",
    "                pi_loss = - torch.mean(torch.min(pi_loss_1, pi_loss_2))\n",
    "                \n",
    "                pi_loss.backward()\n",
    "                self.pi_optimizer.step()\n",
    "                self.pi_optimizer.zero_grad()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "548366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(env, agent, runs=100, agent2 = None):\n",
    "    s = 0\n",
    "    for i in range(runs):\n",
    "        s+=butle(env,agent,is_agent_first = True)\n",
    "    for i in range(runs):\n",
    "        s+=butle(env,agent,is_agent_first = False)\n",
    "    return s/2/runs\n",
    "        \n",
    "\n",
    "def butle(env, agent, agent2 = None, is_agent_first = True):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    agent.l_epsilon = 0\n",
    "    while not done:\n",
    "        if t%2 == (is_agent_first+1)%2:\n",
    "            state = state.reshape(-1)\n",
    "            logits = agent.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "            action = np.argmax(logits.detach().numpy())\n",
    "            state, reward, done, correct = env.step(action)\n",
    "            if done:\n",
    "                return reward\n",
    "        else:\n",
    "            state = state.reshape(-1)\n",
    "            if agent2 == None:\n",
    "                action = np.random.randint(agent.action_dim)\n",
    "            else:\n",
    "                logits = agent2.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "                action = np.argmax(logits.detach().numpy())\n",
    "            state, reward, done, correct = env.step(action)\n",
    "            if done:\n",
    "                return -reward\n",
    "        t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d5814a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeAdvanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c524c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 6.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "state_dim = env.observation_space[0]**2\n",
    "action_dim = env.action_space['n']\n",
    "print(action_dim)\n",
    "\n",
    "agent = PPO(state_dim, action_dim, gamma=-0.95)\n",
    "\n",
    "total_rewards = []\n",
    "validation = []\n",
    "wins = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "146d0ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 6.00\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36mPPO.fit\u001b[1;34m(self, states, actions, rewards, dones)\u001b[0m\n\u001b[0;32m     81\u001b[0m b_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_pi(b_states)\n\u001b[0;32m     82\u001b[0m b_dist \u001b[38;5;241m=\u001b[39m Categorical(b_logits)\n\u001b[1;32m---> 83\u001b[0m b_new_log_probs \u001b[38;5;241m=\u001b[39m \u001b[43mb_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m b_ratio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(b_new_log_probs \u001b[38;5;241m-\u001b[39m b_old_log_probs)\n\u001b[0;32m     86\u001b[0m pi_loss_1 \u001b[38;5;241m=\u001b[39m b_ratio \u001b[38;5;241m*\u001b[39m b_advantage\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\categorical.py:123\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[0;32m    122\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m value, log_pmf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(value, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m)\n\u001b[0;32m    124\u001b[0m value \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_pmf\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, value)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\utils.py:110\u001b[0m, in \u001b[0;36mlazy_property.__get__\u001b[1;34m(self, instance, obj_type)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _lazy_property_and_property(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 110\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28msetattr\u001b[39m(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, value)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\categorical.py:90\u001b[0m, in \u001b[0;36mCategorical.logits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;129m@lazy_property\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogits\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprobs_to_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\utils.py:92\u001b[0m, in \u001b[0;36mprobs_to_logits\u001b[1;34m(probs, is_binary)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_binary:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlog(ps_clamped) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog1p(\u001b[38;5;241m-\u001b[39mps_clamped)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mps_clamped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "episode_n = 300\n",
    "trajectory_n = 50\n",
    "\n",
    "for episode in range(episode_n):\n",
    "\n",
    "    states, actions, rewards, dones = [], [], [], []\n",
    "    \n",
    "    agent.to_cpu()\n",
    "    for _ in range(trajectory_n):\n",
    "        total_reward = 0\n",
    "\n",
    "        state = env.reset()\n",
    "        state = state.reshape(-1)\n",
    "        for t in range(30):\n",
    "            states.append(state*(-1)**(t%2+1))\n",
    "            \n",
    "            action = agent.get_action(state*(-1)**(t%2+1))\n",
    "            actions.append(action)\n",
    "            \n",
    "            state, reward, done, correct = env.step(action)\n",
    "            state = state.reshape(-1)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                if reward>0:\n",
    "                    wins.append(state)\n",
    "                break\n",
    "            \n",
    "        total_rewards.append(total_reward)\n",
    "    if(episode%10==0):\n",
    "        validation.append(validate(env,agent,100))\n",
    "    agent.to_dev()\n",
    "    agent.fit(states, actions, rewards, dones)\n",
    "    agent.l_epsilon -= 0.015\n",
    "    if agent.l_epsilon <= 0.15:\n",
    "        agent.l_epsilon = 0.15\n",
    "    \n",
    "    print(episode,validation[-1],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3c6cb24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bc9d624070>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "39395336",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.l_epsilon = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9753cabb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "tensor([0.1106, 0.2159, 0.1560, 0.3230, 0.1946], grad_fn=<SoftmaxBackward0>)\n",
      "3 3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]]\n",
      "tensor([0.0778, 0.2009, 0.1065, 0.1829, 0.4319], grad_fn=<SoftmaxBackward0>)\n",
      "4 4\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1. -1.]]\n",
      "tensor([0.0899, 0.3547, 0.2598, 0.1605, 0.1351], grad_fn=<SoftmaxBackward0>)\n",
      "1 3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "tensor([0.7515, 0.0672, 0.0961, 0.0462, 0.0389], grad_fn=<SoftmaxBackward0>)\n",
      "0 1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)2\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "tensor([0.1632, 0.2228, 0.1800, 0.2010, 0.2330], grad_fn=<SoftmaxBackward0>)\n",
      "4 1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)2\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "tensor([0.0386, 0.8008, 0.0336, 0.0769, 0.0501], grad_fn=<SoftmaxBackward0>)\n",
      "1 1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [ 1. -1.  0. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "tensor([0.1005, 0.0340, 0.3284, 0.2368, 0.3003], grad_fn=<SoftmaxBackward0>)\n",
      "2 1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1. -1.  0. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0.  0.]\n",
      " [ 1.  1. -1.  0. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "tensor([0.1156, 0.0972, 0.1812, 0.2508, 0.3552], grad_fn=<SoftmaxBackward0>)\n",
      "4 2\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0. -1.]\n",
      " [ 1.  1. -1.  0. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "1-th player turn to act (enter number from 1 to 5)4\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0. -1.]\n",
      " [ 1.  1. -1.  1. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "tensor([0.1663, 0.2509, 0.0735, 0.2043, 0.3050], grad_fn=<SoftmaxBackward0>)\n",
      "4 4\n",
      "100\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0. -1.]\n",
      " [ 1.  1.  1.  0. -1.]\n",
      " [ 1.  1. -1.  1. -1.]\n",
      " [ 1. -1.  1. -1. -1.]]\n",
      "ROBOT WIN\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "t = 0\n",
    "agent.l_epsilon = 0\n",
    "agent.to_cpu()\n",
    "while not done:\n",
    "    if t%2 == 0:\n",
    "        state = state.reshape(-1)\n",
    "        logits = agent.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "        print(logits)\n",
    "        action = agent.get_action(state*(-1)**(t%2+1))\n",
    "        print(np.argmax(logits.detach().numpy()),action)\n",
    "        state, reward, done, correct = env.step(np.argmax(logits.detach().numpy()))\n",
    "        print(reward)\n",
    "        env.render()\n",
    "        if done:\n",
    "            print(\"ROBOT WIN\")\n",
    "    else:\n",
    "        action = int(input(f'{env.player_index}-th player turn to act (enter number from 1 to {env.n})')) - 1\n",
    "        state, reward, done, correct = env.step(action)\n",
    "        print(reward)\n",
    "        env.render()\n",
    "        if done:\n",
    "            print(\"YOU WIN\")\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc30fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "while not done:\n",
    "    action = int(input(f'{env.player_index}-th player turn to act (enter number from 1 to {env.n})')) - 1\n",
    "    state, reward, done, correct = env.step(action)\n",
    "    print(reward)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218768ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  1.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0.  1.]\n",
      " [-0. -1. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [-1.  1.  1.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -1.]\n",
      " [-0. -0. -0. -0.  1.]\n",
      " [ 1. -1. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -1.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [-0. -1. -0. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [ 0.  1.  0.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [-0. -1. -0. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [-1.  1.  0.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0.  1.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [-1. -1.  0.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0.  1.]\n",
      " [-1. -1. -0. -0.  1.]\n",
      " [ 1.  1. -0. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1. -0. -0. -0.  1.]\n",
      " [-1. -1. -0. -0.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 1. -1.  0.  0. -1.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1.  1. -0. -0.  1.]\n",
      " [-1. -1. -0. -1.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 1. -1.  0.  0. -1.]\n",
      " [ 1.  1. -1.  1. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1.  1. -1. -0.  1.]\n",
      " [-1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "100 True -1\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "t = 0\n",
    "while not done:\n",
    "    print(state*(-1)**(t%2+1))\n",
    "    state = state.reshape(-1)\n",
    "    action = agent.get_action(state)\n",
    "    state, reward, done, correct = env.step(action)\n",
    "    print(reward,done,(-1)**(t%2+1))\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f906e4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c7d1599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6317faa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -1. -0.]\n",
      " [-1.  1. -0. -1. -0.]\n",
      " [-1.  1. -0.  1. -0.]\n",
      " [ 1.  1. -0. -1. -0.]]\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  1.  0.]\n",
      " [ 1. -1.  0.  1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]\n",
      " [-1. -1.  0.  1.  0.]]\n",
      "[[ 0. -1.  0.  0.  0.]\n",
      " [ 0.  1.  0. -1.  0.]\n",
      " [ 1. -1.  0.  1.  0.]\n",
      " [-1.  1.  1.  1.  0.]\n",
      " [ 1. -1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(states[i].reshape(5,5))\n",
    "print(actions[i])\n",
    "print(states[i+1].reshape(5,5))\n",
    "print(wins[100].reshape(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f9be199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d0488f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(25, 256), nn.LeakyReLU(0.1),\n",
    "                nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
    "                nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
    "                nn.Linear(256, 256), nn.LeakyReLU(0.1),\n",
    "                nn.Linear(256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e7899a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0047],\n",
       "        [-0.0136],\n",
       "        [-0.0080]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.FloatTensor(wins[1:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2be87c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m wins[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(wins)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(wins)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m not_wins \u001b[38;5;241m=\u001b[39m \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdones\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(dones))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dones))\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "train_data = wins[:int(len(wins)*2/3)]\n",
    "print(int(len(wins)*2/3))\n",
    "not_wins = states[np.array(dones) == False]\n",
    "print(np.array(dones))\n",
    "print(len(dones))\n",
    "idxs = np.random.permutation(len(not_wins))\n",
    "not_wins = not_wins[idxs]\n",
    "\n",
    "print(int(len(wins)))\n",
    "print(int(len(wins)*2/3))\n",
    "print(len(not_wins[:int(len(wins)*2/3)]))\n",
    "train_data.extend(not_wins[:int(len(wins)*2/3)])\n",
    "\n",
    "print(len(train_data))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf9c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d84db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d6b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ed4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768441a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d8fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a77aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1684d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd831429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52230372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236b573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc04e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd83a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213150c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f733174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266f60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25128c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
