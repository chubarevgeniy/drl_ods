{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33dc1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TicTacToeEnv import TicTacToeAdvanced\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Categorical\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c02a768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, gamma=0.99, batch_size=128, \n",
    "                 epsilon=0.3, epoch_n=50, pi_lr=1e-3, v_lr=1e-3):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        self.device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.pi_model_base = nn.Sequential(nn.Linear(state_dim, 128), nn.LeakyReLU(0.1),\n",
    "                                           nn.Linear(128, 128), nn.LeakyReLU(0.1),\n",
    "                                      nn.Linear(128, 128), nn.LeakyReLU(0.1)).to(self.device)\n",
    "        self.pi_model_m = nn.Sequential(nn.Linear(128, action_dim), nn.Softmax()).to(self.device)\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.l_epsilon = 1\n",
    "        self.epsilon = epsilon\n",
    "        self.epoch_n = epoch_n\n",
    "        self.pi_optimizer = torch.optim.Adam(\n",
    "            list(self.pi_model_base.parameters())+list(self.pi_model_m.parameters()),\n",
    "            lr=pi_lr)\n",
    "        \n",
    "    def forward_pi(self, state):\n",
    "        x = self.pi_model_base(state)\n",
    "        \n",
    "        return self.pi_model_m(x)\n",
    "\n",
    "    def get_action(self, state, rand_factor = 1):\n",
    "        logits = self.forward_pi(torch.FloatTensor(state))\n",
    "        norm = torch.ones((self.action_dim,))/self.action_dim\n",
    "        logits_ = (1-self.l_epsilon)*logits + self.l_epsilon*norm\n",
    "        dist = Categorical(logits_)\n",
    "        action = dist.sample()\n",
    "        return action.numpy()\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        self.pi_model_base.to('cpu')\n",
    "        self.pi_model_m.to('cpu')\n",
    "        \n",
    "    def to_dev(self):\n",
    "        self.pi_model_base.to(self.device)\n",
    "        self.pi_model_m.to(self.device)\n",
    "\n",
    "    def fit(self, states, actions, rewards, dones):\n",
    "        \n",
    "        states, actions, rewards, dones = map(np.array, [states, actions, rewards, dones])\n",
    "        rewards, dones = rewards.reshape(-1, 1), dones.reshape(-1, 1)\n",
    "\n",
    "        returns = np.zeros(rewards.shape)\n",
    "        returns[-1] = rewards[-1]\n",
    "        for t in range(returns.shape[0] - 2, -1, -1):\n",
    "            returns[t] = rewards[t] + (1 - dones[t]) * self.gamma * returns[t + 1]\n",
    "\n",
    "        states, actions, returns = map(torch.FloatTensor, [states, actions, returns])\n",
    "        states, actions, returns = states.to(self.device), actions.to(self.device), returns.to(self.device)\n",
    "\n",
    "        logits = self.forward_pi(states)\n",
    "        norm = (torch.ones((self.action_dim,))/self.action_dim).to(self.device)\n",
    "        logits_ = (1-self.l_epsilon)*logits + self.l_epsilon*norm\n",
    "        dist = Categorical(logits_)\n",
    "        old_log_probs = dist.log_prob(actions).detach()\n",
    "\n",
    "        for epoch in range(self.epoch_n):\n",
    "            \n",
    "            idxs = np.random.permutation(returns.shape[0])\n",
    "            for i in range(0, returns.shape[0], self.batch_size):\n",
    "                b_idxs = idxs[i: i + self.batch_size]\n",
    "                b_states = states[b_idxs]\n",
    "                b_actions = actions[b_idxs]\n",
    "                b_returns = returns[b_idxs]\n",
    "                b_old_log_probs = old_log_probs[b_idxs]\n",
    "    \n",
    "                b_advantage = b_returns.detach()\n",
    "                \n",
    "                b_logits = self.forward_pi(b_states)\n",
    "                b_dist = Categorical(b_logits)\n",
    "                b_new_log_probs = b_dist.log_prob(b_actions)\n",
    "    \n",
    "                b_ratio = torch.exp(b_new_log_probs - b_old_log_probs)\n",
    "                pi_loss_1 = b_ratio * b_advantage.detach()\n",
    "                pi_loss_2 = torch.clamp(b_ratio, 1. - self.epsilon,  1. + self.epsilon) * b_advantage.detach()\n",
    "                pi_loss = - torch.mean(torch.min(pi_loss_1, pi_loss_2))\n",
    "                \n",
    "                pi_loss.backward()\n",
    "                self.pi_optimizer.step()\n",
    "                self.pi_optimizer.zero_grad()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "548366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(env, agent, runs=100, agent2 = None):\n",
    "    s = 0\n",
    "    for i in range(runs):\n",
    "        s+=butle(env,agent,is_agent_first = True)\n",
    "    for i in range(runs):\n",
    "        s+=butle(env,agent,is_agent_first = False)\n",
    "    return s/2/runs\n",
    "        \n",
    "\n",
    "def butle(env, agent, agent2 = None, is_agent_first = True):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    agent.l_epsilon = 0\n",
    "    while not done:\n",
    "        if t%2 == (is_agent_first+1)%2:\n",
    "            state = state.reshape(-1)\n",
    "            logits = agent.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "            action = np.argmax(logits.detach().numpy())\n",
    "            state, reward, done, correct = env.step(action)\n",
    "            if done:\n",
    "                return reward\n",
    "        else:\n",
    "            state = state.reshape(-1)\n",
    "            if agent2 == None:\n",
    "                action = np.random.randint(agent.action_dim)\n",
    "            else:\n",
    "                logits = agent2.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "                action = np.argmax(logits.detach().numpy())\n",
    "            state, reward, done, correct = env.step(action)\n",
    "            if done:\n",
    "                return -reward\n",
    "        t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d5814a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeAdvanced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c524c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "state_dim = env.observation_space[0]**2\n",
    "action_dim = env.action_space['n']\n",
    "print(action_dim)\n",
    "\n",
    "agent = PPO(state_dim, action_dim, gamma=-0.95)\n",
    "\n",
    "total_rewards = []\n",
    "validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "146d0ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 18.5\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36mPPO.get_action\u001b[1;34m(self, state, rand_factor)\u001b[0m\n\u001b[0;32m     32\u001b[0m norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim,))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim\n\u001b[0;32m     33\u001b[0m logits_ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_epsilon)\u001b[38;5;241m*\u001b[39mlogits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_epsilon\u001b[38;5;241m*\u001b[39mnorm\n\u001b[1;32m---> 34\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m action \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\categorical.py:64\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     63\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\distribution.py:53\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# skip checking lazily-constructed args\u001b[39;00m\n\u001b[0;32m     52\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[1;32m---> 53\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\distributions\\constraints.py:406\u001b[0m, in \u001b[0;36m_Simplex.check\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(value \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "episode_n = 200\n",
    "trajectory_n = 100\n",
    "\n",
    "for episode in range(episode_n):\n",
    "\n",
    "    states, actions, rewards, dones = [], [], [], []\n",
    "    \n",
    "    agent.to_cpu()\n",
    "    for _ in range(trajectory_n):\n",
    "        total_reward = 0\n",
    "\n",
    "        state = env.reset()\n",
    "        state = state.reshape(-1)\n",
    "        for t in range(30):\n",
    "            states.append(state*(-1)**(t%2+1))\n",
    "            \n",
    "            action = agent.get_action(state*(-1)**(t%2+1))\n",
    "            actions.append(action)\n",
    "            \n",
    "            state, reward, done, correct = env.step(action)\n",
    "            state = state.reshape(-1)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        total_rewards.append(total_reward)\n",
    "    if(episode%10==0):\n",
    "        validation.append(validate(env,agent))\n",
    "    agent.to_dev()\n",
    "    agent.fit(states, actions, rewards, dones)\n",
    "    agent.l_epsilon -= 0.015\n",
    "    if agent.l_epsilon <= 0.15:\n",
    "        agent.l_epsilon = 0.15\n",
    "    \n",
    "    print(episode,validation[-1],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3c6cb24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e400838fa0>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "39395336",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.l_epsilon = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "63144979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "tensor([0.1370, 0.1791, 0.2008, 0.3908, 0.0923], grad_fn=<SoftmaxBackward0>)\n",
      "3 3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]]\n",
      "tensor([0.0935, 0.1872, 0.2155, 0.3572, 0.1467], grad_fn=<SoftmaxBackward0>)\n",
      "3 3\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]\n",
      " [ 1.  0.  0. -1.  0.]]\n",
      "tensor([0.1323, 0.2599, 0.1189, 0.2374, 0.2515], grad_fn=<SoftmaxBackward0>)\n",
      "1 4\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)1\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]]\n",
      "tensor([0.8269, 0.0221, 0.0408, 0.0806, 0.0296], grad_fn=<SoftmaxBackward0>)\n",
      "0 0\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0. -1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)2\n",
      "0\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]]\n",
      "tensor([0.5323, 0.1059, 0.1649, 0.1508, 0.0461], grad_fn=<SoftmaxBackward0>)\n",
      "0 3\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1.  0.]\n",
      " [ 1. -1.  0. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)3\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  0. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "tensor([0.1948, 0.1420, 0.5821, 0.0363, 0.0448], grad_fn=<SoftmaxBackward0>)\n",
      "2 0\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  1. -1. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)3\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0.  0.]\n",
      " [ 1.  1. -1. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "tensor([0.2212, 0.0960, 0.5962, 0.0378, 0.0488], grad_fn=<SoftmaxBackward0>)\n",
      "2 2\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0. -1.  0.  0.]\n",
      " [ 1.  0.  1.  0.  0.]\n",
      " [ 1.  1. -1. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "1-th player turn to act (enter number from 1 to 5)4\n",
      "0\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0. -1.  0.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 1.  1. -1. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "tensor([0.3417, 0.2301, 0.2438, 0.0902, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "0 2\n",
      "100\n",
      "[[-1.  0.  0.  0.  0.]\n",
      " [-1.  0. -1.  0.  0.]\n",
      " [ 1. -1.  1.  1.  0.]\n",
      " [ 1.  1. -1. -1.  0.]\n",
      " [ 1. -1.  1. -1.  0.]]\n",
      "ROBOT WIN\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "t = 0\n",
    "agent.l_epsilon = 0\n",
    "while not done:\n",
    "    if t%2 == 0:\n",
    "        state = state.reshape(-1)\n",
    "        logits = agent.forward_pi(torch.FloatTensor(state*(-1)**(t%2+1)))\n",
    "        print(logits)\n",
    "        action = agent.get_action(state*(-1)**(t%2+1))\n",
    "        print(np.argmax(logits.detach().numpy()),action)\n",
    "        state, reward, done, correct = env.step(np.argmax(logits.detach().numpy()))\n",
    "        print(reward)\n",
    "        env.render()\n",
    "        if done:\n",
    "            print(\"ROBOT WIN\")\n",
    "    else:\n",
    "        action = int(input(f'{env.player_index}-th player turn to act (enter number from 1 to {env.n})')) - 1\n",
    "        state, reward, done, correct = env.step(action)\n",
    "        print(reward)\n",
    "        env.render()\n",
    "        if done:\n",
    "            print(\"YOU WIN\")\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc30fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "while not done:\n",
    "    action = int(input(f'{env.player_index}-th player turn to act (enter number from 1 to {env.n})')) - 1\n",
    "    state, reward, done, correct = env.step(action)\n",
    "    print(reward)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218768ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  1.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0.  1.]\n",
      " [-0. -1. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [-1.  1.  1.  0. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -1.]\n",
      " [-0. -0. -0. -0.  1.]\n",
      " [ 1. -1. -1. -0.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -1.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [-0. -1. -0. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [ 0.  1.  0.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [-0. -1. -0. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [-1.  1.  0.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0. -0.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -0. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [ 0. -1.  0.  0.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0.  1.]\n",
      " [-0. -1. -0. -0.  1.]\n",
      " [-0.  1. -0. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 0.  1.  0.  0. -1.]\n",
      " [-1. -1.  0.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-0. -0. -0. -0.  1.]\n",
      " [-1. -1. -0. -0.  1.]\n",
      " [ 1.  1. -0. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 0.  0.  0.  0. -1.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1. -0. -0. -0.  1.]\n",
      " [-1. -1. -0. -0.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 1. -1.  0.  0. -1.]\n",
      " [ 1.  1.  0.  0. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1.  1. -0. -0.  1.]\n",
      " [-1. -1. -0. -1.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "0 False -1\n",
      "[[ 1. -1.  0.  0. -1.]\n",
      " [ 1.  1. -1.  1. -1.]\n",
      " [-1. -1. -1.  1.  1.]\n",
      " [-1.  1.  1.  1. -1.]\n",
      " [-1.  1.  1. -1. -1.]]\n",
      "0 False 1\n",
      "[[-1.  1. -1. -0.  1.]\n",
      " [-1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1. -1. -1.]\n",
      " [ 1. -1. -1. -1.  1.]\n",
      " [ 1. -1. -1.  1.  1.]]\n",
      "100 True -1\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "t = 0\n",
    "while not done:\n",
    "    print(state*(-1)**(t%2+1))\n",
    "    state = state.reshape(-1)\n",
    "    action = agent.get_action(state)\n",
    "    state, reward, done, correct = env.step(action)\n",
    "    print(reward,done,(-1)**(t%2+1))\n",
    "    t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f906e4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c7d1599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317faa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
